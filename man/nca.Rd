% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nca.R, R/predict.R
\name{nca}
\alias{nca}
\alias{nca.fit}
\alias{print.nca}
\alias{predict.nca}
\title{Neighborhood Components Analysis}
\usage{
nca(formula, data, neighborhood, subset, na.action, ...)

nca.fit(
  y,
  X,
  n_components,
  init = c("pca", "identity"),
  loss = NULL,
  mode = c("classification", "regression"),
  ...,
  neighborhood = NULL,
  lambda = 0,
  optim_method = "L-BFGS-B",
  optim_control = list(),
  debug = FALSE
)

\method{print}{nca}(x, ...)

\method{predict}{nca}(object, newdata, ..., neighborhood = NULL, na.action = stats::na.pass)
}
\arguments{
\item{formula}{A formula denoting the response and features.}

\item{data}{An optional data.frame from which to get the variables in \code{formula}.}

\item{neighborhood}{An indicator of a distinct neighborhood,
for when, a priori, the data is completely separable into distinct groups
(that is, \code{p_ij} can be rearranged to be block diagonal); having this
prior knowledge of which points structurally can and can't be neighbors speeds
up computation}

\item{subset}{An optional vector specifying the subset of rows to use.}

\item{na.action}{The action to take when \code{NA}s are present.}

\item{...}{Other arguments passed to \code{model.matrix} or \code{nca.fit} or \code{loss}.}

\item{y}{The response vector whose loss is to be measured. This can be a factor
or character vector, for which classification will be performed, or a numeric,
for which regression will be performed.}

\item{X}{A matrix of N data points (rows) by K features (columns).}

\item{n_components}{How many components to use for the NCA algorithm.}

\item{init}{How to initialize the transformation matrix. This can either be a
numeric matrix from which to start the gradient descent, or a string denoting
"pca" inits or "identity" matrix inits.}

\item{loss}{A vectorized function fed to \code{\link{outer}} for determining
the loss between two elements of \code{y}. It is assumed (but not checked)
that the loss is symmetric. For regression, this defaults to \code{\link{loss_sq_error}},
and for classification it defaults to \code{\link{loss_misclassification}}.}

\item{mode}{One of "classification" or "regression". If this argument is missing,
it is inferred based on the class of \code{y}.}

\item{lambda}{A penalty parameter to penalize the transformation matrix back to 0. The penalty applied
is \code{1/2 * lambda * sum(transformation^2)}.}

\item{optim_method}{The method passed to \code{\link{optim}}.}

\item{optim_control}{The control passed to \code{\link{optim}}. It can be
useful for, e.g., increasing verbosity of the optimization.}

\item{debug}{A logical, for debugging}

\item{object, x}{An object of class \code{'nca'}}

\item{newdata}{New data to predict}
}
\description{
Neighborhood Components Analysis
}
\details{
This differs from the NCA publication (Goldberger et al.) in a few ways.
 First, it uses a vectorized
gradient; second, it minimizes loss instead of maximizing accuracy (hence it
can support regression); third, it supports a penalty parameter (\code{lambda},
as in Yang et al.).
}
\examples{
library(datasets)
data(iris)

nca.iris <- nca(Species ~ ., data = iris, n_components = 1)
pred <- fitted(nca.iris)
table(colnames(pred)[apply(pred, 1, which.max)] == iris$Species) # 2\% Leave-One-Out error

}
\references{
J. Goldberger, G. Hinton, S. Roweis, R. Salakhutdinov.
"Neighbourhood Components Analysis". Advances in Neural Information
Processing Systems. 17, 513-520, 2005.

Yang, W., K. Wang, W. Zuo. "Neighborhood Component Feature Selection for
High-Dimensional Data." Journal of Computers. Vol. 7, Number 1, January, 2012.
}
